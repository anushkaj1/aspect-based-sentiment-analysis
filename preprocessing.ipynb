{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is preprocessed such that the XML data is converted to CSV form which can be easily accessed using pandas dataframes. \n",
    "\n",
    "Final data is stored in the following form:\n",
    "\n",
    "- Files in the `preprocessed_datasets/sentences` directory contain basic information for each sentence including `rewiev_id`, `sentence_id`, `text` with `sentence_id` as the primary key.\n",
    "- Files in the `preprocessed_datasets/opinions` directory contain information regarding each opinion for every sentence including `setence_id`, `opinion_id`, `target`, `category`, `polarity`, `from`, `to` with `opinion_id` as the primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m248.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/anushka/anaconda3/envs/smai/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/anushka/anaconda3/envs/smai/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/anushka/anaconda3/envs/smai/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/anushka/anaconda3/envs/smai/lib/python3.11/site-packages (from nltk) (4.66.1)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirc = \"./datasets/\"\n",
    "dircs = \"./preprocessed_datasets/sentences/\"\n",
    "dirco = \"./preprocessed_datasets/opinions/\"\n",
    "\n",
    "files = [\n",
    "    \"arabic-hotels\",\n",
    "    \"chinese-cameras\",\n",
    "    \"chinese-phones\",\n",
    "    \"dutch-phones\",\n",
    "    \"dutch-restaurants\",\n",
    "    \"english-laptops\",\n",
    "    \"english-restaurants\",\n",
    "    \"french-restaurants\",\n",
    "    \"russian-restaurants\",\n",
    "    \"spanish-restaurants\",\n",
    "    \"turkish-restaurants\"\n",
    "]\n",
    "\n",
    "xml = \".xml\"\n",
    "csv = \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing data into new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfs = []\n",
    "odfs = []\n",
    "for i in range(len(files)):\n",
    "    tree = ET.parse(dirc + files[i] + xml)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    sentences = []\n",
    "    opinions = []\n",
    "\n",
    "    for elem in root:\n",
    "        rid = elem.attrib['rid']\n",
    "\n",
    "        for sntnc in elem[0]:\n",
    "            sentence = {}\n",
    "            sentence[\"rid\"] = rid\n",
    "            sentence[\"id\"] = sntnc.attrib['id']\n",
    "            sentence[\"text\"] = sntnc.find('text').text\n",
    "            sentences.append(sentence)\n",
    "\n",
    "            if len(sntnc) > 1:\n",
    "                for i in range(len(sntnc[1])):\n",
    "                    op = sntnc[1][i]\n",
    "                    opinion = {}\n",
    "                    opinion[\"sid\"] = sentence[\"id\"]\n",
    "                    opinion[\"id\"] = sentence[\"id\"] + \":\" + str(i)\n",
    "                    for key in op.attrib.keys():\n",
    "                        opinion[key] = op.attrib[key]\n",
    "                    opinions.append(opinion)\n",
    "\n",
    "    sdf = pd.DataFrame(sentences)\n",
    "    odf = pd.DataFrame(opinions)\n",
    "    sdfs.append(sdf)\n",
    "    odfs.append(odf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sdfs)):\n",
    "    sdf = sdfs[i]\n",
    "    odf = odfs[i]\n",
    "    sdf.to_csv(dircs + files[i] + csv, index=False)\n",
    "    odf.to_csv(dirco + files[i] + csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b1fe00-a3ad-4d1c-92f9-d79f7417fc27",
   "metadata": {},
   "source": [
    "# Using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "id": "c8fabc71-8b7a-4acd-b539-170ee391065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import one_hot\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97663481-8843-497e-97c8-54a960248db0",
   "metadata": {},
   "source": [
    "## Helper Functions \n",
    "- `parse_review` : parses the `.xml` file (dataset) for a given language domain pair and extracts all reviews along with the aspect and sentiment\n",
    "- `remove_non_alpha` : for all english sentences, removes all non alphabet characters\n",
    "- `pad_collate` : while loading the data as batches into the dataloader, this deals with the varying sequence lengths (by either padding or truncating)\n",
    "- `initialize_random_embeddings` : used to create aspect embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "id": "0b830056-a2df-49fe-b8ba-98ddc86f3d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def parse_review(review):\n",
    "    return list(map(lambda sen: (sen.find('text').text,\\\n",
    "                    tuple(map(lambda op: (op.attrib[\"category\"],op.attrib[\"polarity\"]),sen.find(\"Opinions\").findall('Opinion')))),\\\n",
    "                    list(filter(lambda sen: sen.find(\"Opinions\"), review.find(\"sentences\").findall(\"sentence\")))))\n",
    "\n",
    "def remove_non_alpha(sentence):\n",
    "    cleaned_sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "    return cleaned_sentence\n",
    "\n",
    "def get_all_entities_attributes(all_aspects):\n",
    "    all_entities = []\n",
    "    all_attributes = []\n",
    "    for aspect in all_aspects:\n",
    "        entity, attribute = aspect.split(\"#\")\n",
    "        all_entities.append(entity)\n",
    "        all_attributes.append(attribute)\n",
    "    return all_entities, all_attributes\n",
    "\n",
    "def initialize_random_embeddings(entities, attributes, embedding_dim):\n",
    "    entity_embeddings = nn.Embedding(len(entities), embedding_dim)\n",
    "    attribute_embeddings = nn.Embedding(len(attributes), embedding_dim)\n",
    "    return entity_embeddings, attribute_embeddings\n",
    "\n",
    "def get_aspect_embedding(aspect, entity_embeddings, attribute_embeddings):\n",
    "    entity, attribute = aspect.split(\"#\")\n",
    "    entity_embedding = entity_embeddings(torch.LongTensor([all_entities.index(entity)]))\n",
    "    attribute_embedding = attribute_embeddings(torch.LongTensor([all_attributes.index(attribute)]))\n",
    "    aspect_embedding = (entity_embedding + attribute_embedding) / 2\n",
    "    return aspect_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7543d-2f80-49c9-943a-495c40d09ec0",
   "metadata": {},
   "source": [
    "# Aspect Category Detection\n",
    "- In this task, we pass to our CNN model the embedded sentence as input and the aspect associated with each sentence as the label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a763d-2405-4be2-aabb-8ea48210a9b5",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- We use our helper functions to parse the XML file, tokenise all the sentences and create vocabularies (for words and for aspects) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "id": "7230ade8-35c4-40ae-958d-c8da11275faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all reviews\n",
    "tree = ET.parse(\"./datasets/english-restaurants.xml\")\n",
    "root = tree.getroot()\n",
    "all_reviews = list(map(parse_review, root.findall(\"Review\")))\n",
    "train_reviews, test_reviews = train_test_split(total_reviews, train_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "id": "5eb237b0-5f62-4577-bf9a-033c76bf953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sentences and aspects\n",
    "train_sentences, test_sentences = [], []\n",
    "train_aspects, test_aspects = [], []\n",
    "\n",
    "# Train \n",
    "for review in train_reviews:\n",
    "    for sentence in review:\n",
    "        cleaned_sentence = remove_non_alpha(sentence[0])\n",
    "        if (len(cleaned_sentence) != 0):\n",
    "            train_sentences.append(cleaned_sentence)\n",
    "            train_aspects.append(sentence[1][0][0])\n",
    "\n",
    "# Test\n",
    "for review in test_reviews:\n",
    "    for sentence in review:\n",
    "        cleaned_sentence = remove_non_alpha(sentence[0])\n",
    "        if (len(cleaned_sentence) != 0):\n",
    "            test_sentences.append(cleaned_sentence)\n",
    "            test_aspects.append(sentence[1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "id": "038cf274-c40a-4118-9dda-1100d57d06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenising sentences and creating the vocabularies\n",
    "tokenization = lambda x: x.split()\n",
    "\n",
    "# for sentences\n",
    "unique_tokens = set([token for sentence in all_sentences for token in tokenization(sentence)])\n",
    "vocab = {token: idx for idx, token in enumerate(unique_tokens)}\n",
    "\n",
    "# for aspects\n",
    "unique_aspects = set(all_aspects)\n",
    "aspect_vocab = {aspect: idx for idx, aspect in enumerate(unique_aspects)}\n",
    "aspect_vocab_reverse = {v: k for k, v in aspect_vocab.items()}\n",
    "num_unique_aspects = len(unique_aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4310247c-dc76-428f-9c06-4000c174d2d1",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader\n",
    "- We define a custom dataset class to load our tokenised sentences, along with the aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "id": "ced87486-4bd5-483b-854d-64127aefcc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspectExtractionDataset(Dataset):\n",
    "    def __init__(self, sentences, aspects, tokenizer, vocab, aspect_vocab):\n",
    "        self.sentences = sentences\n",
    "        self.aspects = aspects\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "        self.aspect_vocab = aspect_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.tokenizer(self.sentences[index])\n",
    "        aspect = [self.aspect_vocab[self.aspects[index]]]\n",
    "        return sentence, aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "3f2f46e2-c03f-43bc-bb99-1a16907afd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_aspect_extraction(batch):\n",
    "    sentences, aspects = zip(*batch)\n",
    "    padded_sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor([vocab[token] for token in sentence]) for sentence in sentences], batch_first=True)\n",
    "    one_hot_aspects = one_hot(torch.tensor(aspects), num_classes=num_unique_aspects)\n",
    "    return padded_sentences, one_hot_aspects.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "82eeae94-443d-40d1-afc3-700b4d8c5603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the dataset and dataloader\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 1\n",
    "aspect_extraction_train_dataset = AspectExtractionDataset(train_sentences, train_aspects, tokenization, vocab, aspect_vocab)\n",
    "aspect_extraction_train_dataloader = DataLoader(aspect_extraction_train_dataset, batch_size=BATCH_SIZE, collate_fn=pad_collate_aspect_extraction, shuffle=True)\n",
    "\n",
    "# Testing\n",
    "# aspect_extraction_test_dataset = AspectExtractionDataset(test_sentences, test_aspects, tokenization, vocab, aspect_vocab)\n",
    "# aspect_extraction_test_dataloader = DataLoader(aspect_extraction_test_dataset, batch_size=BATCH_SIZE, collate_fn=pad_collate_aspect_extraction, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ea223-fd38-4ee8-852e-22cea3a5b005",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "- Here, we use a simple CNN to learn and predict the aspects for a given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "b324d24a-4604-4479-9515-8052449a1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspectExtractionCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, aspect_vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 128, kernel_size=3, padding=3)\n",
    "        self.conv2 = nn.Conv1d(128, 512, kernel_size=3, padding=3)\n",
    "        self.fc = nn.Linear(512, aspect_vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.long())\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv2(self.conv1(x))\n",
    "        x = torch.max(x, dim=2)[0]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72013587-3ff1-4336-8e28-9b1f93edbd45",
   "metadata": {},
   "source": [
    "## Train and Eval\n",
    "- We define functions to train the model and evaluate it by making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "8dcba2e1-533e-46d8-9419-652af6213012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "7f093fd0-5a55-4dc4-b808-1a868412dcb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_aspects(outputs, aspect_vocab, threshold):\n",
    "    outputs = torch.softmax(outputs, dim=1)\n",
    "    predicted_aspects = [aspect for aspect, prob in aspect_vocab.items() if outputs[0][prob] >= threshold]\n",
    "    return predicted_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "id": "84e29337-5dab-4f14-af71-0b426b1e2e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d11057c42fe4dc9bcc73d198f9fdfd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.094722\n",
      "Epoch 2/10, Loss: 0.664143\n",
      "Epoch 3/10, Loss: 0.045833\n",
      "Epoch 4/10, Loss: 0.000037\n",
      "Epoch 5/10, Loss: 0.000253\n",
      "Epoch 6/10, Loss: 0.106663\n",
      "Epoch 7/10, Loss: 5.612749\n",
      "Epoch 8/10, Loss: 0.000566\n",
      "Epoch 9/10, Loss: 0.000001\n",
      "Epoch 10/10, Loss: -0.000000\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "# Hyperparameters\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "ASPECT_VOCAB_SIZE = len(aspect_vocab)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "model_aspect_extraction = AspectExtractionCNN(VOCAB_SIZE, EMBEDDING_DIM, ASPECT_VOCAB_SIZE).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_aspect_extraction.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS), desc=\"Training Epochs\"):\n",
    "    epoch_loss = train(model_aspect_extraction, aspect_extraction_train_dataloader, criterion, optimizer, device)\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {epoch_loss:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "id": "21bbfcde-7a38-4775-9854-ca88c161b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : AMBIENCE#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#STYLE_OPTIONS']\n",
      "True Aspect(s) : FOOD#PRICES | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : AMBIENCE#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL', 'SERVICE#GENERAL']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['SERVICE#GENERAL']\n",
      "True Aspect(s) : LOCATION#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['AMBIENCE#GENERAL', 'FOOD#QUALITY']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['SERVICE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#STYLE_OPTIONS']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : DRINKS#PRICES | Predicted Aspect(s): ['SERVICE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#MISCELLANEOUS | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : AMBIENCE#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#PRICES']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['SERVICE#GENERAL']\n",
      "True Aspect(s) : AMBIENCE#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['SERVICE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#STYLE_OPTIONS | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : FOOD#STYLE_OPTIONS | Predicted Aspect(s): ['AMBIENCE#GENERAL', 'FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : FOOD#STYLE_OPTIONS | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#MISCELLANEOUS | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : LOCATION#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#PRICES']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : LOCATION#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL', 'RESTAURANT#MISCELLANEOUS']\n",
      "True Aspect(s) : AMBIENCE#GENERAL | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['SERVICE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#MISCELLANEOUS | Predicted Aspect(s): ['RESTAURANT#MISCELLANEOUS']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : DRINKS#QUALITY | Predicted Aspect(s): ['AMBIENCE#GENERAL', 'FOOD#QUALITY']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['RESTAURANT#GENERAL', 'RESTAURANT#PRICES']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL', 'RESTAURANT#MISCELLANEOUS']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : LOCATION#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['AMBIENCE#GENERAL']\n",
      "True Aspect(s) : SERVICE#GENERAL | Predicted Aspect(s): ['SERVICE#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n",
      "True Aspect(s) : RESTAURANT#MISCELLANEOUS | Predicted Aspect(s): ['RESTAURANT#MISCELLANEOUS']\n",
      "True Aspect(s) : FOOD#QUALITY | Predicted Aspect(s): ['FOOD#QUALITY', 'FOOD#STYLE_OPTIONS']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#MISCELLANEOUS']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['FOOD#QUALITY']\n",
      "True Aspect(s) : AMBIENCE#GENERAL | Predicted Aspect(s): ['FOOD#PRICES']\n",
      "True Aspect(s) : RESTAURANT#GENERAL | Predicted Aspect(s): ['RESTAURANT#GENERAL']\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "test_dataset = AspectExtractionDataset(test_sentences, test_aspects, tokenization, vocab, aspect_vocab)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, collate_fn=pad_collate_aspect_extraction, shuffle=True)\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, targets in test_dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model_aspect_extraction(inputs)\n",
    "    predicted_aspects = predict_aspects(outputs, aspect_vocab, threshold=0.25)\n",
    "    print(f\"True Aspect(s) : {aspect_vocab_reverse[torch.argmax(targets).item()]} | Predicted Aspect(s): {predicted_aspects}\")\n",
    "    if (predicted_aspects[0] == aspect_vocab_reverse[torch.argmax(targets).item()]):\n",
    "        correct += 1\n",
    "    total +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "id": "e3f0d5e1-52b2-4d6a-ae52-6a26b52a5b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 58.0247%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy : {correct*100/total:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e1d89a-8606-4f2b-987b-61fbb06cb409",
   "metadata": {},
   "source": [
    "# Sentiment Polarity\n",
    "- In this task, we pass to our model the sentence embeddings and along with it the aspect embeddings. The associated sentiment is passed as the label. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a1fcd-512d-4cd4-8b4c-dba3466a72c2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "id": "4c9a7c88-17ac-46e5-891d-7a9f4158bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all reviews\n",
    "tree = ET.parse(\"./datasets/english-restaurants.xml\")\n",
    "root = tree.getroot()\n",
    "all_reviews = list(map(parse_review, root.findall(\"Review\")))\n",
    "train_reviews, test_reviews = train_test_split(total_reviews, train_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "id": "1f3ba9e6-03c8-40c0-977e-e9e196331bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sentences and aspects\n",
    "train_sentences, test_sentences = [], []\n",
    "train_aspects, test_aspects = [], []\n",
    "train_sentiments, test_sentiments = [], []\n",
    "\n",
    "# Train \n",
    "for review in train_reviews:\n",
    "    for sentence in review:\n",
    "        cleaned_sentence = remove_non_alpha(sentence[0])\n",
    "        if (len(cleaned_sentence) != 0):\n",
    "            train_sentences.append(cleaned_sentence)\n",
    "            train_aspects.append(sentence[1][0][0])\n",
    "            if (sentence[1][0][-1] == 'positive'):\n",
    "                train_sentiments.append(1)\n",
    "            elif (sentence[1][0][-1] == 'negative'):\n",
    "                train_sentiments.append(2)\n",
    "            elif (sentence[1][0][-1] == 'neutral'):\n",
    "                train_sentiments.append(3)\n",
    "\n",
    "# Test\n",
    "for review in test_reviews:\n",
    "    for sentence in review:\n",
    "        cleaned_sentence = remove_non_alpha(sentence[0])\n",
    "        if (len(cleaned_sentence) != 0):\n",
    "            test_sentences.append(cleaned_sentence)\n",
    "            test_aspects.append(sentence[1][0][0])\n",
    "            if (sentence[1][0][-1] == 'positive'):\n",
    "                train_sentiments.append(1)\n",
    "            elif (sentence[1][0][-1] == 'negative'):\n",
    "                train_sentiments.append(2)\n",
    "            elif (sentence[1][0][-1] == 'neutral'):\n",
    "                train_sentiments.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "3dcd9af6-222a-4734-9b43-1e63253f4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_sentiment = {0: 'positive', 1: 'negative', 2: 'neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "id": "6b6bd07a-eeae-46ed-a535-a5778a13753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenising sentences and creating the vocabularies\n",
    "tokenization = lambda x: x.split()\n",
    "\n",
    "# for sentences\n",
    "unique_tokens = set([token for sentence in train_sentences for token in tokenization(sentence)])\n",
    "vocab = {token: idx for idx, token in enumerate(unique_tokens)}\n",
    "\n",
    "# tokenising sentences\n",
    "tokenised_sentences_train = [torch.tensor([vocab[token] for token in tokenization(sentence)]) for sentence in train_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "id": "13f42e9b-0b22-4146-947a-2e91190817e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities, all_attributes = get_all_entities_attributes(train_aspects)\n",
    "entity_embeddings, attribute_embeddings = initialize_random_embeddings(all_entities, all_attributes, embedding_dim=15)\n",
    "embedded_aspects = {}\n",
    "for aspect in train_aspects:\n",
    "    aspect_embedding = get_aspect_embedding(aspect, entity_embeddings, attribute_embeddings)\n",
    "    embedded_aspects[aspect] = aspect_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "5561faad-5243-4ad2-8320-74166447627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_sentences = []\n",
    "aspect_embeddings = []\n",
    "for i, sentence in enumerate(train_sentences):\n",
    "    sent_tokenised = torch.tensor([vocab[token] for token in tokenization(sentence)])\n",
    "    tokenised_sentences.append(sent_tokenised)\n",
    "    aspect_embeddings.append(embedded_aspects[train_aspects[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe6871-2d50-4182-8fe0-7d810e59228c",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "id": "392745e3-7169-478b-a05b-7050671058a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentPolarityDataset(Dataset):\n",
    "    def __init__(self, tokenised_sentences, aspect_embeddings, sentiments):\n",
    "        self.tokenised_sentences = tokenised_sentences\n",
    "        self.aspect_embeddings = aspect_embeddings\n",
    "        self.sentiments = sentiments\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.sentiments_labels_encoded = self.label_encoder.fit_transform(self.sentiments)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenised_sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'tokenised_sentence': self.tokenised_sentences[index],\n",
    "            'aspect_embedding': self.aspect_embeddings[index][0],\n",
    "            'label': self.sentiments_labels_encoded[index]\n",
    "        }\n",
    "sentiment_polarity_dataset = SentimentPolarityDataset(tokenised_sentences, aspect_embeddings, train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "id": "7816f996-ba4e-40bc-898f-8e9f5bf9878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_sentiment_polarity(batch):\n",
    "    sentences = [torch.LongTensor(item['tokenised_sentence']) for item in batch]\n",
    "    aspects = [item['aspect_embedding'] for item in batch]\n",
    "    labels = torch.LongTensor([item['label'] for item in batch])\n",
    "    padded_sentences = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
    "    return {\n",
    "        'padded_sentence': padded_sentences,\n",
    "        'aspect_embedding': torch.stack(aspects),\n",
    "        'label': labels\n",
    "    }\n",
    "# Create DataLoader instances with collate function\n",
    "sentiment_polarity_dataloader = DataLoader(sentiment_polarity_dataset, batch_size=1, shuffle=True, collate_fn=pad_collate_sentiment_polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3566093e-fca7-4cec-a139-1bfb664d5a51",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "id": "5fb9d5e4-65ec-4315-8d19-2a9c05f13924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentPolarityCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, aspect_input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.aspect_linear = nn.Linear(aspect_input_size, embedding_dim)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 128, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x_sentence, x_aspect):\n",
    "        x_sentence = self.embedding(x_sentence)\n",
    "        x_sentence = x_sentence.permute(0, 2, 1)\n",
    "        x_aspect = self.aspect_linear(x_aspect)\n",
    "        x_aspect = x_aspect.unsqueeze(2)\n",
    "        x_concat = torch.cat((x_sentence, x_aspect), dim=2)\n",
    "        x_conv = self.conv1(x_concat)\n",
    "        x_pool = torch.max(x_conv, dim=2)[0]\n",
    "        output = self.fc(x_pool)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374acdb5-87c8-482e-99ad-97929940dfac",
   "metadata": {},
   "source": [
    "## Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "id": "74cf5ceb-8ce8-4079-b052-84fb681b6552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7810dd61268b49d4baa6753575bb9704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 1.2227\n",
      "Epoch 2/15, Loss: 1.1146\n",
      "Epoch 3/15, Loss: 0.7416\n",
      "Epoch 4/15, Loss: 0.5937\n",
      "Epoch 5/15, Loss: 0.6082\n",
      "Epoch 6/15, Loss: 0.5591\n",
      "Epoch 7/15, Loss: 0.5654\n",
      "Epoch 8/15, Loss: 0.5571\n",
      "Epoch 9/15, Loss: 0.5595\n",
      "Epoch 10/15, Loss: 0.5574\n",
      "Epoch 11/15, Loss: 0.5534\n",
      "Epoch 12/15, Loss: 0.5545\n",
      "Epoch 13/15, Loss: 0.5532\n",
      "Epoch 14/15, Loss: 0.5539\n",
      "Epoch 15/15, Loss: 0.5531\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 50 \n",
    "aspect_input_size = 15\n",
    "num_classes = len(sentiment_polarity_dataset.label_encoder.classes_)\n",
    "model_sentiment_polarity = SentimentPolarityCNN(vocab_size, embedding_dim, aspect_input_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_sentiment_polarity.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 15\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Performance does NOT improve beyond 10 epochs -> early stopping\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "    for batch in train_dataloader:\n",
    "        padded_sentence, aspect_embedding, labels = (batch['padded_sentence'],batch['aspect_embedding'],batch['label'])\n",
    "        padded_sentence, aspect_embedding, labels = (padded_sentence.to(device),aspect_embedding.to(device),labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_sentiment_polarity(padded_sentence, aspect_embedding)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "6ba782de-66f8-4cda-85bf-c60aa14fb552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : positive | Predicted Sentiment : positive\n",
      "Actual Sentiment : neutral | Predicted Sentiment : neutral\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n",
      "Actual Sentiment : negative | Predicted Sentiment : negative\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for batch in train_dataloader:\n",
    "    padded_sentence, aspect_embedding, labels = (batch['padded_sentence'],batch['aspect_embedding'],batch['label'])\n",
    "    padded_sentence, aspect_embedding, labels = (padded_sentence.to(device),aspect_embedding.to(device),labels.to(device))\n",
    "    outputs = model_sentiment_polarity(padded_sentence, aspect_embedding)\n",
    "    prediction = idx_to_sentiment[torch.argmax(outputs).item()]\n",
    "    label = idx_to_sentiment[labels.item()]\n",
    "    print(f\"Actual Sentiment : {label} | Predicted Sentiment : {prediction}\")\n",
    "    if (prediction == label):\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "8d91dfe1-255c-4af6-b0f5-2da440d8b86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.0000%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy : {correct*100/total:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
